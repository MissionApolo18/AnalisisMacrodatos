{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S04_SparkSTFLocatel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/12 15:36:35 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"locatel.txt\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum, to_date, to_timestamp, regexp_replace,date_format\n",
    "from pyspark.sql.types import IntegerType, DoubleType, FloatType\n",
    "\n",
    "dir_hdfs:\"hdfs://namenode:9000/tmp/amd/locatel0311\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(dir_hdfs, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()\n",
    "\n",
    "print(f\"Número de renglones: {df.count()}\")\n",
    "print(f\"Número de columnas: {len(df.columns())}\")\n",
    "print(f\"Columnas: {df.columns()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = df.select(['fecha_solicitud','hora_solicitud','tema_solicitud','sexo',\n",
    "                   'edad','estatus','alcaldia','colonia_datos','latitud','longitud'])\n",
    "\n",
    "datos.printSchema()\n",
    "datos.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.filter('sexo = \"FEMENINO\"').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = df.select(['fecha_solicitud','hora_solicitud','tema_solicitud','sexo',\n",
    "                   'edad','estatus','alcaldia','colonia_datos','latitud','longitud']).filter('sexo = \"FEMENINO\"').orderBy('fecha_solicitud').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = datos.withColumn('fecha_solicitud', to_date(col('fecha_solicitud'),\"yyyy-MM-dd\")).\\\n",
    "    withColumn('edad',col(\"fecha_solicitud\").cast(FloatType())).\\\n",
    "    withColumn('latitud',col(\"latitud\").cast(DoubleType())).\\\n",
    "    withColumn('longitud',col(\"longitud\").cast(DoubleType()))\n",
    "\n",
    "datos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase 27/09/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contar nulos\n",
    "datos.select([sum(col(c).isNull().cast(int)).alias(c) for c in datos.columns()]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour, minute, second, year, month, dayofmonth\n",
    "\n",
    "datos_tiempo = datos.select(col(\"edad\"),col(\"estatus\"),col(\"tema_solicitud\"),\n",
    "                            year(col(col)).alias(\"anio\"))\n",
    "datos_tiempo.printSchema()\n",
    "datos_tiempo.describe().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['anio','mes','dia','hora','minuto','segundo','semana']\n",
    "datos_tiempo.select(columnas).describe().show()\n",
    "datos_tiempo.select(columnas).describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver datos únicos\n",
    "datos_tiempo.select(\"tema_solicitud\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_tiempo.select(\"tema_solicitud\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_tiempo.select(\"tema_solicitud\").count().orderBy(\"tema_solicitud\").\\\n",
    "show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_tiempo.select(\"tema_solicitud\").count().orderBy(\"count\",ascending=False).\\\n",
    "show(100,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase 30/09/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Localhost:4040\n",
    "datos_tiempo.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_tiempo.filter(datos_tiempo.anio==2020).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_tiempo.filter(datos_tiempo.anio==2020).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_tiempo.select(['edad','anio','nombre_dia','hora','estatus']).filter((datos_tiempo.anio==2020) and (datos_tiempo<=6)).\\\n",
    "    filter(datos_tiempo.nombre_dia ==\"Sunday\").filter(datos_tiempo.edad>0).\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.groupBy(\"alcaldia\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.groupBy(\"alcaldia\").count().show(100,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.groupBy(\"alcaldia\").agg({\"edad\":\"avg\"}).show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.write.csv(\"hdfs://namenode:9000/tmp/amd/locateltiempo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S05_SparkSTFLocatel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.write.mode(\"\").cvs(\"hdfs://namenode:9000/tmp/amd/locateltiempo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.select(\"*\", (dft.edad * 12).alias(\"edad_meses\")).show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.select(\"*\", (dft.edad * 12).\\\n",
    "           alias(\"edad_meses\")write.mode(\"overwrite\").\\\n",
    "            cvs(\"hdfs://namenode:9000/tmp/amd/locateltiempo\", header = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.select(\"*\", (dft.edad * 12).\\\n",
    "           alias(\"edad_meses\")write.mode(\"overwrite\").\\\n",
    "            cvs(\"hdfs://namenode:9000/tmp/amd/locateltiempo\", header = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count\n",
    "datos_tiempo.groupBy(\"anio\", \"mes\").agg(count(\"*\").alias(\"nr\")).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_tiempo.select([\"edad\",\"estatus\",\"tema_solicitud\", \"anio\",\"mes\"])\\\n",
    "            .partitionBy(\"anio\")\\\n",
    "            .write.mode(\"append\")\\\n",
    "            .cvs(\"hdfs://namenode:9000/tmp/amd/locateltiempobyanio\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = spark.read.option(header = True)\\\n",
    "           .cvs(\"hdfs://namenode:9000/tmp/amd/locateltiempobyanioymes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.show(30, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.filter('mes = 7 AND anio = 2022').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase 07/10/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum, to_date, to_timestamp, regexp_replace\n",
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql.types import IntergerType, DoubleType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_hdfs = \"hdfs://namenode:9000/tmp/amd/locatel0311\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import agg, max, min, count\n",
    "\n",
    "dfg = datos.groupBy(\"alcaldia\").\\\n",
    "    agg(avg(\"edad\").alias(\"edad_promedio\")\n",
    "                max(\"edad\").alias(\"edad_maxima\")\n",
    "                min(\"edad\").alias(\"edad_minima\")\n",
    "                count(\"*\").alias(\"no_registros\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.groupBy(\"alcaldia_solicitud\",ascendig = False).show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "datos = datos.\\\n",
    "    withColumn(\"alcaldia_solicitud\", when(datos.alcaldia_solicitud == \"IZTACALCO\", \"iZTACALCO\")).\\\n",
    "    otherwise(datos.alcaldia_solicitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import truncate\n",
    "datos.groupBy(\"alcaldia\").\\\n",
    "    agg(avg(\"edad\").alias(\"edad_promedio\")\n",
    "                max(\"edad\").alias(\"edad_maxima\")\n",
    "                min(\"edad\").alias(\"edad_minima\")\n",
    "                count(\"*\").alias(\"no_registros\")).\\\n",
    "    orderBy(\"alcaldia_solicitud\",ascending = False).\\\n",
    "    show(100,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepomex_df = spark.read.\\\n",
    "    option(\"header\", \"True\").option(\"delimiter\", \"|\").\\\n",
    "    option(\"skipRows\", \"1\")sch(schema).\\\n",
    "    csv(\"hdfs://namenode:9000/tmp/amd/sepomex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcp = sepomex_df.select(['d_codigo','D_mnpio','d_estado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepomex_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcp.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, coalesce\n",
    "\n",
    "datos_mapeados = datos.join(dfcp.select([\"d_codigo\", \"D_mnpio\"]), datos[\"codigo_postal_solicitud\"] == dfcp[\"d_codigo\"], \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mapeados.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mapeados.select([\"codigo_postal_solicitud\", \"alcaldia_solicitud\", \"d_codigo\", \"D_mnpio\"]).show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mapeados.withColumn(\"alcaldia\", coalesce(col(\"D_mnpio\"), col(\"alcaldia\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mapeados.select([\"edad\", \"alcadia\", \"codigo_postal_solicitud\",\"d_codigo\"]).show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificar duplicados\n",
    "dfcp_dup = dfcp.groupBy(\"d_codigo\").agg(count(\"*\").alias(\"count\")).\\\n",
    "    filter(\"count\" > 1)\n",
    "\n",
    "print(dfcp_dup.count())\n",
    "dfcp_dup.orderBy(\"count\", ascending = True).show(100,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ver duplicados\n",
    "dfcp.filter(\"d_codigo = 85203\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar duplicados\n",
    "dfcp = dfcp.dropDuplicates(\"d_codigo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validar que ya no hay duplicados\n",
    "dfcp.groupBy(\"d_codigo\").agg(count(\"*\").alias(\"count\")).filter(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lpad, regexp_replace, trim\n",
    "datos = datos.withColumn(\n",
    "    \"codigo_postal_solicitud\", lpad (\n",
    "        trim(\n",
    "          regexp_replace (\n",
    "              col(\n",
    "                  \"codigo_postal_solicitud\"),\"[0-9]\", \"\")\n",
    "        ), 5, \"0\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.select(\"codigo_postal_solicitud\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.select(\"codigo_postal_solicitud\" == \"00000\").\\\n",
    "    dropDup([\"codigo_postal_solicitud\"]).\\\n",
    "    filter(\"codigo_postal_solicitud\") and (len(col(\"alcaldia\")==5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actualizar codigo postal, cambiarlo por alcaldía\n",
    "datos = datos.withColumn(\"codigo_postal_solicitud\" when (\n",
    "         (col(\"codigo_postal_solicitud\") = \"00000\")\n",
    "            and (lenght(col(\"alcaldia\")) = 5),\n",
    "         col(\"alcaldia_solicitud\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.select(\"alcaldia\",\"codigo_psotal_solicitud\").filter(\n",
    "    col(\"codigo_postal_solicitud\") == col (\"alcaldia\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = datos_mapeados.groupBy(\"alcaldia\").agg(\n",
    "    avg(\"edad\").alias(\"edad_promedio\"),\n",
    "    max(\"edad\").alias(\"edad_maxima\"),\n",
    "    min(\"edad\").alias(\"edad_minima\"),\n",
    "    count(\"*\").alias(\"no_registros\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.orderBy(\"alcaldia_solicitud\",ascendig = False).show(100,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mapeados.write.mode(\"overwrite\").option(\"heeader\",\"true\").csv(\"hdfs://namenode:9000/tmp/amd/locatellimpio\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
